{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "I did not change anything here except number of epochs. Is there any reason to tune anything?\n",
    "Keras automatically resizes images, so no need to worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 19:30:19.483176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import keras.backend as K\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "TRAINING_DATA_DIR = 'training/'\n",
    "VALID_DATA_DIR = 'validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 848 images belonging to 2 classes.\n",
      "Found 210 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAINING_DATA_DIR,\n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SHAPE,\n",
    ")\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    VALID_DATA_DIR,\n",
    "    shuffle=False,\n",
    "    target_size=IMAGE_SHAPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 19:30:32.615748: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def build_model(num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', \n",
    "                           input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "model = build_model(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                692256    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 699,730\n",
      "Trainable params: 699,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[get_f1]\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 42s 1s/step - loss: 0.6803 - get_f1: 0.5661 - val_loss: 0.6755 - val_get_f1: 0.5417\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.6503 - get_f1: 0.5853 - val_loss: 0.6344 - val_get_f1: 0.6094\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 39s 1s/step - loss: 0.6048 - get_f1: 0.6058 - val_loss: 0.5902 - val_get_f1: 0.6458\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 46s 2s/step - loss: 0.5768 - get_f1: 0.6466 - val_loss: 0.5556 - val_get_f1: 0.6667\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 38s 1s/step - loss: 0.5334 - get_f1: 0.6875 - val_loss: 0.5480 - val_get_f1: 0.6667\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.4979 - get_f1: 0.7007 - val_loss: 0.4919 - val_get_f1: 0.6927\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.4888 - get_f1: 0.6995 - val_loss: 0.4803 - val_get_f1: 0.7292\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 40s 2s/step - loss: 0.4735 - get_f1: 0.7079 - val_loss: 0.5224 - val_get_f1: 0.6823\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 41s 2s/step - loss: 0.4662 - get_f1: 0.7043 - val_loss: 0.4632 - val_get_f1: 0.7552\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.4350 - get_f1: 0.7536 - val_loss: 0.4559 - val_get_f1: 0.7448\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // BATCH_SIZE // 2,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps= valid_generator.samples // BATCH_SIZE // 2,\n",
    "                    verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('igor_alentev')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f7231cd321bc73172e23d3fd2b7413e5063c7e51a3c02201c1a1feb0b5bad5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
